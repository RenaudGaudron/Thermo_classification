{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thermoacoustic stability prediction using multilabel classification algorithms\n",
    "### Part 1: Models\n",
    "\n",
    "The objective of this project is to predict the thermoacoustic stability of a combustor in various frequency intervals using multilabel classification algorithms.\n",
    "\n",
    "---\n",
    "\n",
    "Data source: Artificial data generated with a modified version of OSCILOS_lite (freely available at https://github.com/MorgansLab/OSCILOS_lite)\n",
    "\n",
    "---\n",
    "\n",
    "Author: Renaud Gaudron\\\n",
    "Version: 6.0\\\n",
    "Latest update: 18/08/21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Preprocessing of the artificial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening and printing to log file\n",
    "\n",
    "sourceFile = open('Multilabel_Classification_log.txt', 'w')\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------------\\n\",file=sourceFile)\n",
    "print(\"Thermoacoustic stability prediction using multilabel classification algorithms\\n\".upper(),file=sourceFile)\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------------\\n\",file=sourceFile)\n",
    "print(\"Data source: Artificial data generated with a modified version of OSCILOS_lite (freely available at https://github.com/MorgansLab/OSCILOS_lite)\\n\",file=sourceFile)\n",
    "print(\"Author: Renaud Gaudron\\n\",file=sourceFile)\n",
    "print(\"Version: 6.0\\n\",file=sourceFile)\n",
    "print(\"Latest update: 18/08/21\\n\",file=sourceFile)\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------------\\n\",file=sourceFile)\n",
    "print(\"Step 1 : Preprocessing of the artificial data\".upper(),file=sourceFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>R0</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>Gain</th>\n",
       "      <th>Phase</th>\n",
       "      <th>0_50</th>\n",
       "      <th>50_100</th>\n",
       "      <th>100_150</th>\n",
       "      <th>150_200</th>\n",
       "      <th>200_250</th>\n",
       "      <th>250_300</th>\n",
       "      <th>300_350</th>\n",
       "      <th>350_400</th>\n",
       "      <th>400_450</th>\n",
       "      <th>450_500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.215282</td>\n",
       "      <td>0.323424</td>\n",
       "      <td>0.170701</td>\n",
       "      <td>0.082752</td>\n",
       "      <td>0.053804</td>\n",
       "      <td>0.010102</td>\n",
       "      <td>0.885752</td>\n",
       "      <td>2.551514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.140167</td>\n",
       "      <td>0.188399</td>\n",
       "      <td>0.423352</td>\n",
       "      <td>0.089381</td>\n",
       "      <td>0.089260</td>\n",
       "      <td>0.078452</td>\n",
       "      <td>0.518373</td>\n",
       "      <td>3.134972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.166067</td>\n",
       "      <td>0.111135</td>\n",
       "      <td>0.155982</td>\n",
       "      <td>0.023319</td>\n",
       "      <td>0.084748</td>\n",
       "      <td>0.055220</td>\n",
       "      <td>0.615510</td>\n",
       "      <td>2.905676</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159184</td>\n",
       "      <td>0.338507</td>\n",
       "      <td>0.276718</td>\n",
       "      <td>0.020077</td>\n",
       "      <td>0.042646</td>\n",
       "      <td>0.056869</td>\n",
       "      <td>0.875384</td>\n",
       "      <td>4.900099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.488712</td>\n",
       "      <td>0.281809</td>\n",
       "      <td>0.156784</td>\n",
       "      <td>0.081084</td>\n",
       "      <td>0.035787</td>\n",
       "      <td>0.058883</td>\n",
       "      <td>0.765332</td>\n",
       "      <td>1.543422</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.229345</td>\n",
       "      <td>0.362074</td>\n",
       "      <td>0.343772</td>\n",
       "      <td>0.060946</td>\n",
       "      <td>0.033539</td>\n",
       "      <td>0.052616</td>\n",
       "      <td>0.829335</td>\n",
       "      <td>3.811601</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.172424</td>\n",
       "      <td>0.148255</td>\n",
       "      <td>0.525720</td>\n",
       "      <td>0.045043</td>\n",
       "      <td>0.078339</td>\n",
       "      <td>0.020235</td>\n",
       "      <td>0.982497</td>\n",
       "      <td>4.370344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.631154</td>\n",
       "      <td>0.050756</td>\n",
       "      <td>0.200507</td>\n",
       "      <td>0.069525</td>\n",
       "      <td>0.018376</td>\n",
       "      <td>0.017569</td>\n",
       "      <td>0.756406</td>\n",
       "      <td>2.116734</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.511980</td>\n",
       "      <td>0.048393</td>\n",
       "      <td>0.319640</td>\n",
       "      <td>0.035053</td>\n",
       "      <td>0.022520</td>\n",
       "      <td>0.098560</td>\n",
       "      <td>0.733090</td>\n",
       "      <td>4.961723</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.502112</td>\n",
       "      <td>0.200094</td>\n",
       "      <td>0.108543</td>\n",
       "      <td>0.033783</td>\n",
       "      <td>0.069184</td>\n",
       "      <td>0.019358</td>\n",
       "      <td>0.757796</td>\n",
       "      <td>3.491583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         L1        L2        L3        R0        R1        R2      Gain  \\\n",
       "0  0.215282  0.323424  0.170701  0.082752  0.053804  0.010102  0.885752   \n",
       "1  0.140167  0.188399  0.423352  0.089381  0.089260  0.078452  0.518373   \n",
       "2  0.166067  0.111135  0.155982  0.023319  0.084748  0.055220  0.615510   \n",
       "3  0.159184  0.338507  0.276718  0.020077  0.042646  0.056869  0.875384   \n",
       "4  0.488712  0.281809  0.156784  0.081084  0.035787  0.058883  0.765332   \n",
       "5  0.229345  0.362074  0.343772  0.060946  0.033539  0.052616  0.829335   \n",
       "6  0.172424  0.148255  0.525720  0.045043  0.078339  0.020235  0.982497   \n",
       "7  0.631154  0.050756  0.200507  0.069525  0.018376  0.017569  0.756406   \n",
       "8  0.511980  0.048393  0.319640  0.035053  0.022520  0.098560  0.733090   \n",
       "9  0.502112  0.200094  0.108543  0.033783  0.069184  0.019358  0.757796   \n",
       "\n",
       "      Phase  0_50  50_100  100_150  150_200  200_250  250_300  300_350  \\\n",
       "0  2.551514     0       0        0        0        0        1        0   \n",
       "1  3.134972     0       0        0        0        1        0        0   \n",
       "2  2.905676     0       0        0        0        0        0        1   \n",
       "3  4.900099     0       0        0        1        0        0        0   \n",
       "4  1.543422     0       0        0        0        0        0        1   \n",
       "5  3.811601     0       0        0        0        0        0        0   \n",
       "6  4.370344     0       0        1        0        0        0        1   \n",
       "7  2.116734     0       0        0        0        0        1        0   \n",
       "8  4.961723     0       0        1        0        0        0        0   \n",
       "9  3.491583     0       0        0        1        1        0        0   \n",
       "\n",
       "   350_400  400_450  450_500  \n",
       "0        0        0        0  \n",
       "1        0        0        1  \n",
       "2        0        0        0  \n",
       "3        0        0        0  \n",
       "4        0        0        0  \n",
       "5        0        1        0  \n",
       "6        0        0        0  \n",
       "7        0        0        0  \n",
       "8        0        1        0  \n",
       "9        0        1        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data\n",
    "\n",
    "data = pd.read_csv(\"Cases_large.txt\", sep=\"\\t\",usecols=list(range(20))) # Storing data as a Pandas framework\n",
    "\n",
    "headers=[\"X0\",\"X1\",\"X2\",\"X3\",\"R0\",\"R1\",\"R2\",\"R3\",\"Gain\",\"Phase\",\"0_50\",\"50_100\",\"100_150\",\"150_200\",\n",
    "         \"200_250\",\"250_300\",\"300_350\",\"350_400\",\"400_450\",\"450_500\"] \n",
    "data.columns = headers # Adding headers to the data\n",
    "\n",
    "data[\"0_50\"] = data[\"0_50\"].astype('int') # Change type for the column \"Unstable\" \n",
    "data[\"50_100\"] = data[\"50_100\"].astype('int') # Change type for the column \"Unstable\" \n",
    "data[\"100_150\"] = data[\"100_150\"].astype('int') # Change type for the column \"Unstable\" \n",
    "data[\"150_200\"] = data[\"150_200\"].astype('int') # Change type for the column \"Unstable\" \n",
    "data[\"200_250\"] = data[\"200_250\"].astype('int') # Change type for the column \"Unstable\" \n",
    "data[\"250_300\"] = data[\"250_300\"].astype('int') # Change type for the column \"Unstable\" \n",
    "data[\"300_350\"] = data[\"300_350\"].astype('int') # Change type for the column \"Unstable\" \n",
    "data[\"350_400\"] = data[\"350_400\"].astype('int') # Change type for the column \"Unstable\" \n",
    "data[\"400_450\"] = data[\"400_450\"].astype('int') # Change type for the column \"Unstable\" \n",
    "data[\"450_500\"] = data[\"450_500\"].astype('int') # Change type for the column \"Unstable\" \n",
    "\n",
    "# The stability column indicates whether a combustor is practically stable (0) or a practically unstable (1) for each frequency range\n",
    "\n",
    "# Let's drop columns X0 and R3 as they are redundant\n",
    "data=data.drop(columns=['X0','R3'])\n",
    "\n",
    "# X represents the absolute axial position of the element. Let's compute Li=Xi-Xi-1 corresponding to the length of each element.\n",
    "\n",
    "data['X3']=data['X3']-data['X2']\n",
    "data['X2']=data['X2']-data['X1']\n",
    "\n",
    "data.rename(columns={\"X1\":\"L1\"}, inplace=True) # We just need to change the heading for this one\n",
    "data.rename(columns={\"X2\":\"L2\"}, inplace=True) # We just need to change the heading for this one\n",
    "data.rename(columns={\"X3\":\"L3\"}, inplace=True) # We just need to change the heading for this one\n",
    "\n",
    "#data=data[:100] # FOR VALIDATION ONLY - Select the first 100 examples\n",
    "\n",
    "print(\"\\nTop 10 lines of the pre-processed data:\\n\",file=sourceFile)\n",
    "print(round(data.head(10),4).to_markdown(index = False, tablefmt=\"fancy_grid\"),file=sourceFile)\n",
    "\n",
    "data.head(10) # Display the top 10 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L1         float64\n",
       "L2         float64\n",
       "L3         float64\n",
       "R0         float64\n",
       "R1         float64\n",
       "R2         float64\n",
       "Gain       float64\n",
       "Phase      float64\n",
       "0_50         int64\n",
       "50_100       int64\n",
       "100_150      int64\n",
       "150_200      int64\n",
       "200_250      int64\n",
       "250_300      int64\n",
       "300_350      int64\n",
       "350_400      int64\n",
       "400_450      int64\n",
       "450_500      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes # Checking the data types for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548203 stable configurations - 3154 unstable configurations between 0-50 Hz.\n",
      "522296 stable configurations - 29061 unstable configurations between 50-100 Hz.\n",
      "476755 stable configurations - 74602 unstable configurations between 100-150 Hz.\n",
      "470435 stable configurations - 80922 unstable configurations between 150-200 Hz.\n",
      "497355 stable configurations - 54002 unstable configurations between 200-250 Hz.\n",
      "494253 stable configurations - 57104 unstable configurations between 250-300 Hz.\n",
      "467536 stable configurations - 83821 unstable configurations between 300-350 Hz.\n",
      "461529 stable configurations - 89828 unstable configurations between 350-400 Hz.\n",
      "470144 stable configurations - 81213 unstable configurations between 400-450 Hz.\n",
      "472000 stable configurations - 79357 unstable configurations between 450-500 Hz.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n{} stable configurations - {} unstable configurations between 0-50 Hz.\".format(data[\"0_50\"].value_counts()[0],data[\"0_50\"].value_counts()[1]),file=sourceFile)\n",
    "print(\"{} stable configurations - {} unstable configurations between 0-50 Hz.\".format(data[\"0_50\"].value_counts()[0],data[\"0_50\"].value_counts()[1]))\n",
    "\n",
    "print(\"{} stable configurations - {} unstable configurations between 50-100 Hz.\".format(data[\"50_100\"].value_counts()[0],data[\"50_100\"].value_counts()[1]),file=sourceFile)\n",
    "print(\"{} stable configurations - {} unstable configurations between 50-100 Hz.\".format(data[\"50_100\"].value_counts()[0],data[\"50_100\"].value_counts()[1]))\n",
    "\n",
    "print(\"{} stable configurations - {} unstable configurations between 100-150 Hz.\".format(data[\"100_150\"].value_counts()[0],data[\"100_150\"].value_counts()[1]),file=sourceFile)\n",
    "print(\"{} stable configurations - {} unstable configurations between 100-150 Hz.\".format(data[\"100_150\"].value_counts()[0],data[\"100_150\"].value_counts()[1]))\n",
    "\n",
    "print(\"{} stable configurations - {} unstable configurations between 150-200 Hz.\".format(data[\"150_200\"].value_counts()[0],data[\"150_200\"].value_counts()[1]),file=sourceFile)\n",
    "print(\"{} stable configurations - {} unstable configurations between 150-200 Hz.\".format(data[\"150_200\"].value_counts()[0],data[\"150_200\"].value_counts()[1]))\n",
    "\n",
    "print(\"{} stable configurations - {} unstable configurations between 200-250 Hz.\".format(data[\"200_250\"].value_counts()[0],data[\"200_250\"].value_counts()[1]),file=sourceFile)\n",
    "print(\"{} stable configurations - {} unstable configurations between 200-250 Hz.\".format(data[\"200_250\"].value_counts()[0],data[\"200_250\"].value_counts()[1]))\n",
    "\n",
    "print(\"{} stable configurations - {} unstable configurations between 250-300 Hz.\".format(data[\"250_300\"].value_counts()[0],data[\"250_300\"].value_counts()[1]),file=sourceFile)\n",
    "print(\"{} stable configurations - {} unstable configurations between 250-300 Hz.\".format(data[\"250_300\"].value_counts()[0],data[\"250_300\"].value_counts()[1]))\n",
    "\n",
    "print(\"{} stable configurations - {} unstable configurations between 300-350 Hz.\".format(data[\"300_350\"].value_counts()[0],data[\"300_350\"].value_counts()[1]),file=sourceFile)\n",
    "print(\"{} stable configurations - {} unstable configurations between 300-350 Hz.\".format(data[\"300_350\"].value_counts()[0],data[\"300_350\"].value_counts()[1]))\n",
    "\n",
    "print(\"{} stable configurations - {} unstable configurations between 350-400 Hz.\".format(data[\"350_400\"].value_counts()[0],data[\"350_400\"].value_counts()[1]),file=sourceFile)\n",
    "print(\"{} stable configurations - {} unstable configurations between 350-400 Hz.\".format(data[\"350_400\"].value_counts()[0],data[\"350_400\"].value_counts()[1]))\n",
    "\n",
    "print(\"{} stable configurations - {} unstable configurations between 400-450 Hz.\".format(data[\"400_450\"].value_counts()[0],data[\"400_450\"].value_counts()[1]),file=sourceFile)\n",
    "print(\"{} stable configurations - {} unstable configurations between 400-450 Hz.\".format(data[\"400_450\"].value_counts()[0],data[\"400_450\"].value_counts()[1]))\n",
    "\n",
    "print(\"{} stable configurations - {} unstable configurations between 450-500 Hz.\\n\".format(data[\"450_500\"].value_counts()[0],data[\"450_500\"].value_counts()[1]),file=sourceFile)\n",
    "print(\"{} stable configurations - {} unstable configurations between 450-500 Hz.\".format(data[\"450_500\"].value_counts()[0],data[\"450_500\"].value_counts()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Computing the Kendall correlation coefficients\n",
    "\n",
    "Kendall_corr=data.corr(method='kendall') # Compute the correlation between the different variables\n",
    "Kendall_corr.to_csv(r'Kendall_correlations_Multilabel.csv', index = False) # Storing to a data file\n",
    "\n",
    "print(\"Correlations between the different variables:\\n\",file=sourceFile)\n",
    "print(round(Kendall_corr,3).to_markdown(index = True, tablefmt=\"fancy_grid\"),file=sourceFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Machine Learning setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(551357, 8)\n",
      "(551357, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------------------------------------------------------------\\n\",file=sourceFile)\n",
    "print(\"Step 2 : Machine Learning setup\\n\".upper(),file=sourceFile)\n",
    "\n",
    "# Defining the feature matrix and response vectors\n",
    "\n",
    "X=data[['L1','L2','L3','R0','R1','R2','Gain','Phase']].values # Feature Matrix\n",
    "y=data[['0_50','50_100','100_150','150_200','200_250','250_300','300_350','350_400','400_450','450_500']].values # Response vector\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the feature vector\n",
    "\n",
    "X=preprocessing.StandardScaler().fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set Feature Matrix (441085, 8)\n",
      "Size of testing set Feature Matrix (110272, 8)\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=3)\n",
    "print('Size of training set Feature Matrix {}'.format(X_train.shape),file=sourceFile)\n",
    "print('Size of testing set Feature Matrix {}'.format(X_test.shape),file=sourceFile)\n",
    "print('Size of training set Feature Matrix {}'.format(X_train.shape))\n",
    "print('Size of testing set Feature Matrix {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: K-nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest testing accuracy is 97.501 % obtained for 1 neighbour(s)\n",
      "\n",
      "Elapsed time: 11162.94 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------------------------------------------------------------\\n\",file=sourceFile)\n",
    "print(\"Step 3 : K-nearest neighbours\\n\".upper(),file=sourceFile)\n",
    "\n",
    "## Building the K nearest neighbours (KNN) models\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "Ks=50 # Maximum number of neighbours\n",
    "\n",
    "parameters_Kneigh = [\n",
    "    {\n",
    "        'classifier': [KNeighborsClassifier()],\n",
    "        'classifier__n_neighbors': range(1,Ks+1),\n",
    "    },\n",
    "]\n",
    "\n",
    "search_Kneigh = GridSearchCV(ClassifierChain(), parameters_Kneigh, scoring='accuracy', n_jobs=-1)\n",
    "search_Kneigh.fit(X_train,y_train)\n",
    "\n",
    "pred_Kneigh_test = search_Kneigh.predict(X_test)\n",
    "mean_acc_test=metrics.accuracy_score(y_test,pred_Kneigh_test)\n",
    "\n",
    "print(\"The highest testing accuracy is\",round(100*mean_acc_test,3),\"% obtained for\",search_Kneigh.best_params_['classifier__n_neighbors'], \"neighbour(s)\",file=sourceFile)\n",
    "print(\"\\nElapsed time:\",round((time.time() - t),2),\"seconds\",file=sourceFile)\n",
    "\n",
    "print(\"The highest testing accuracy is\",round(100*mean_acc_test,3),\"% obtained for\",search_Kneigh.best_params_['classifier__n_neighbors'], \"neighbour(s)\")\n",
    "print(\"\\nElapsed time:\",round((time.time() - t),2),\"seconds\")\n",
    "\n",
    "result_Kneigh=search_Kneigh.cv_results_['mean_test_score']\n",
    "np.savetxt(\"Results_Kneigh_Multilabel.csv\", result_Kneigh, delimiter=\",\") # Saving results to a separate file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest testing accuracy is 97.628 % obtained for 37 layer(s)\n",
      "\n",
      "Elapsed time: 849.19 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------------------------------------------------------------\\n\",file=sourceFile)\n",
    "print(\"Step 4 : Decision Trees\\n\".upper(),file=sourceFile)\n",
    "\n",
    "## Building the Decision Trees models\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "Ks=50 # Maximum number of layers\n",
    "\n",
    "parameters_Tree = [\n",
    "    {\n",
    "        'classifier': [DecisionTreeClassifier(criterion=\"entropy\")],\n",
    "        'classifier__max_depth': range(1,Ks+1),\n",
    "    },\n",
    "]\n",
    "\n",
    "search_Tree = GridSearchCV(ClassifierChain(), parameters_Tree, scoring='accuracy', n_jobs=-1)\n",
    "search_Tree.fit(X_train,y_train)\n",
    "\n",
    "pred_Tree_test = search_Tree.predict(X_test)\n",
    "mean_acc_test=metrics.accuracy_score(y_test,pred_Tree_test)\n",
    "\n",
    "print(\"The highest testing accuracy is\",round(100*mean_acc_test,3),\"% obtained for\",search_Tree.best_params_['classifier__max_depth'], \"layer(s)\",file=sourceFile)\n",
    "print(\"\\nElapsed time:\",round((time.time() - t),2),\"seconds\",file=sourceFile)\n",
    "\n",
    "print(\"The highest testing accuracy is\",round(100*mean_acc_test,3),\"% obtained for\",search_Tree.best_params_['classifier__max_depth'], \"layer(s)\")\n",
    "print(\"\\nElapsed time:\",round((time.time() - t),2),\"seconds\")\n",
    "\n",
    "result_Tree=search_Tree.cv_results_['mean_test_score']\n",
    "np.savetxt(\"Results_Tree_Multilabel.csv\", result_Tree, delimiter=\",\") # Saving results to a separate file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgaudron/anaconda3/envs/JupyterLab_env/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest testing accuracy is 98.352 % obtained for 99 tree(s)\n",
      "\n",
      "Elapsed time: 23608.87 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------------------------------------------------------------\\n\",file=sourceFile)\n",
    "print(\"Step 5 : Random forests\\n\".upper(),file=sourceFile)\n",
    "\n",
    "## Building the Random forest models for various numbers of trees in the forest\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "Ks=100 # Maximum number of trees in the forest\n",
    "\n",
    "parameters_Forest = [\n",
    "    {\n",
    "        'classifier': [RandomForestClassifier(criterion='entropy')],\n",
    "        'classifier__n_estimators': range(1,Ks+1),\n",
    "    },\n",
    "]\n",
    "\n",
    "search_Forest = GridSearchCV(ClassifierChain(), parameters_Forest, scoring='accuracy', n_jobs=-1)\n",
    "search_Forest.fit(X_train,y_train)\n",
    "\n",
    "pred_Forest_test = search_Forest.predict(X_test)\n",
    "mean_acc_test=metrics.accuracy_score(y_test,pred_Forest_test)\n",
    "\n",
    "print(\"The highest testing accuracy is\",round(100*mean_acc_test,3),\"% obtained for\",search_Forest.best_params_['classifier__n_estimators'], \"tree(s)\",file=sourceFile)\n",
    "print(\"\\nElapsed time:\",round((time.time() - t),2),\"seconds\",file=sourceFile)\n",
    "\n",
    "print(\"The highest testing accuracy is\",round(100*mean_acc_test,3),\"% obtained for\",search_Forest.best_params_['classifier__n_estimators'], \"tree(s)\")\n",
    "print(\"\\nElapsed time:\",round((time.time() - t),2),\"seconds\")\n",
    "\n",
    "result_Forest=search_Forest.cv_results_['mean_test_score']\n",
    "np.savetxt(\"Results_Forest_Multilabel.csv\", result_Forest, delimiter=\",\") # Saving results to a separate file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Multilayer Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest testing accuracy is 94.205 % obtained with alpha= 0.001 and initial learning rate= 0.001\n",
      "\n",
      "Elapsed time: 187386.37 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------------------------------------------------------------\\n\",file=sourceFile)\n",
    "print(\"Step 6 : Multi-layer Perceptrons\\n\".upper(),file=sourceFile)\n",
    "\n",
    "## Building the Multi-layer Perceptrons models for various numbers of trees in the forest\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "parameters_MLP = [\n",
    "    {\n",
    "        'classifier': [MLPClassifier(solver='adam', activation='relu', hidden_layer_sizes=(100,100,100),\n",
    "                                random_state=1, max_iter=10000, verbose=False, tol=1e-4, batch_size='auto')],\n",
    "        'classifier__alpha': [0.001, 0.003, 0.01, 0.03, 0.1, 0.3],  # Regularisation parameter\n",
    "        'classifier__learning_rate_init': [0.0001, 0.0003, 0.001, 0.003, 0.006, 0.01], # Initial learning rate\n",
    "    },\n",
    "]\n",
    "\n",
    "search_MLP = GridSearchCV(ClassifierChain(), parameters_MLP, scoring='accuracy', n_jobs=-1)\n",
    "search_MLP.fit(X_train,y_train)\n",
    "\n",
    "pred_MLP_test = search_MLP.predict(X_test)\n",
    "mean_acc_test=metrics.accuracy_score(y_test,pred_MLP_test)\n",
    "\n",
    "print(\"The highest testing accuracy is\",round(100*mean_acc_test,3),\"% obtained with alpha=\", search_MLP.best_params_['classifier__alpha'], \"and initial learning rate=\", search_MLP.best_params_['classifier__learning_rate_init'],file=sourceFile)\n",
    "print(\"\\nElapsed time:\",round((time.time() - t),2),\"seconds\",file=sourceFile)\n",
    "\n",
    "print(\"The highest testing accuracy is\",round(100*mean_acc_test,3),\"% obtained with alpha=\", search_MLP.best_params_['classifier__alpha'], \"and initial learning rate=\", search_MLP.best_params_['classifier__learning_rate_init'])\n",
    "print(\"\\nElapsed time:\",round((time.time() - t),2),\"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Closing the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceFile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
