{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thermoacoustic stability prediction using binary classification algorithms\n",
    "### Part 1: Models\n",
    "\n",
    "The objective of this project is to predict the overall thermoacoustic stability of a combustor using binary classification algorithms.\n",
    "\n",
    "---\n",
    "\n",
    "Data source: Artificial data generated with a modified version of OSCILOS_lite (freely available at https://github.com/MorgansLab/OSCILOS_lite)\n",
    "\n",
    "---\n",
    "\n",
    "Author: Renaud Gaudron\\\n",
    "Version: 5.0\\\n",
    "Latest update: 18/08/21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Preprocessing of the artificial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening and printing to log file\n",
    "\n",
    "sourceFile = open('Binary_Classification_log.txt', 'w')\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------------\\n\",file=sourceFile)\n",
    "print(\"Thermoacoustic stability prediction using binary classification algorithms\\n\".upper(),file=sourceFile)\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------------\\n\",file=sourceFile)\n",
    "print(\"Data source: Artificial data generated with a modified version of OSCILOS_lite (freely available at https://github.com/MorgansLab/OSCILOS_lite)\\n\",file=sourceFile)\n",
    "print(\"Author: Renaud Gaudron\\n\",file=sourceFile)\n",
    "print(\"Version: 5.0\\n\",file=sourceFile)\n",
    "print(\"Latest update: 18/08/21\\n\",file=sourceFile)\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------------\\n\",file=sourceFile)\n",
    "print(\"Step 1 : Preprocessing of the artificial data\".upper(),file=sourceFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>R0</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>Gain</th>\n",
       "      <th>Phase</th>\n",
       "      <th>Stability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.215282</td>\n",
       "      <td>0.323424</td>\n",
       "      <td>0.170701</td>\n",
       "      <td>0.082752</td>\n",
       "      <td>0.053804</td>\n",
       "      <td>0.010102</td>\n",
       "      <td>0.885752</td>\n",
       "      <td>2.551514</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.140167</td>\n",
       "      <td>0.188399</td>\n",
       "      <td>0.423352</td>\n",
       "      <td>0.089381</td>\n",
       "      <td>0.089260</td>\n",
       "      <td>0.078452</td>\n",
       "      <td>0.518373</td>\n",
       "      <td>3.134972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.166067</td>\n",
       "      <td>0.111135</td>\n",
       "      <td>0.155982</td>\n",
       "      <td>0.023319</td>\n",
       "      <td>0.084748</td>\n",
       "      <td>0.055220</td>\n",
       "      <td>0.615510</td>\n",
       "      <td>2.905676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159184</td>\n",
       "      <td>0.338507</td>\n",
       "      <td>0.276718</td>\n",
       "      <td>0.020077</td>\n",
       "      <td>0.042646</td>\n",
       "      <td>0.056869</td>\n",
       "      <td>0.875384</td>\n",
       "      <td>4.900099</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.488712</td>\n",
       "      <td>0.281809</td>\n",
       "      <td>0.156784</td>\n",
       "      <td>0.081084</td>\n",
       "      <td>0.035787</td>\n",
       "      <td>0.058883</td>\n",
       "      <td>0.765332</td>\n",
       "      <td>1.543422</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.229345</td>\n",
       "      <td>0.362074</td>\n",
       "      <td>0.343772</td>\n",
       "      <td>0.060946</td>\n",
       "      <td>0.033539</td>\n",
       "      <td>0.052616</td>\n",
       "      <td>0.829335</td>\n",
       "      <td>3.811601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.172424</td>\n",
       "      <td>0.148255</td>\n",
       "      <td>0.525720</td>\n",
       "      <td>0.045043</td>\n",
       "      <td>0.078339</td>\n",
       "      <td>0.020235</td>\n",
       "      <td>0.982497</td>\n",
       "      <td>4.370344</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.631154</td>\n",
       "      <td>0.050756</td>\n",
       "      <td>0.200507</td>\n",
       "      <td>0.069525</td>\n",
       "      <td>0.018376</td>\n",
       "      <td>0.017569</td>\n",
       "      <td>0.756406</td>\n",
       "      <td>2.116734</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.511980</td>\n",
       "      <td>0.048393</td>\n",
       "      <td>0.319640</td>\n",
       "      <td>0.035053</td>\n",
       "      <td>0.022520</td>\n",
       "      <td>0.098560</td>\n",
       "      <td>0.733090</td>\n",
       "      <td>4.961723</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.502112</td>\n",
       "      <td>0.200094</td>\n",
       "      <td>0.108543</td>\n",
       "      <td>0.033783</td>\n",
       "      <td>0.069184</td>\n",
       "      <td>0.019358</td>\n",
       "      <td>0.757796</td>\n",
       "      <td>3.491583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         L1        L2        L3        R0        R1        R2      Gain  \\\n",
       "0  0.215282  0.323424  0.170701  0.082752  0.053804  0.010102  0.885752   \n",
       "1  0.140167  0.188399  0.423352  0.089381  0.089260  0.078452  0.518373   \n",
       "2  0.166067  0.111135  0.155982  0.023319  0.084748  0.055220  0.615510   \n",
       "3  0.159184  0.338507  0.276718  0.020077  0.042646  0.056869  0.875384   \n",
       "4  0.488712  0.281809  0.156784  0.081084  0.035787  0.058883  0.765332   \n",
       "5  0.229345  0.362074  0.343772  0.060946  0.033539  0.052616  0.829335   \n",
       "6  0.172424  0.148255  0.525720  0.045043  0.078339  0.020235  0.982497   \n",
       "7  0.631154  0.050756  0.200507  0.069525  0.018376  0.017569  0.756406   \n",
       "8  0.511980  0.048393  0.319640  0.035053  0.022520  0.098560  0.733090   \n",
       "9  0.502112  0.200094  0.108543  0.033783  0.069184  0.019358  0.757796   \n",
       "\n",
       "      Phase  Stability  \n",
       "0  2.551514          1  \n",
       "1  3.134972          1  \n",
       "2  2.905676          1  \n",
       "3  4.900099          1  \n",
       "4  1.543422          1  \n",
       "5  3.811601          1  \n",
       "6  4.370344          1  \n",
       "7  2.116734          1  \n",
       "8  4.961723          1  \n",
       "9  3.491583          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data\n",
    "\n",
    "data = pd.read_csv(\"Cases_large.txt\", sep=\"\\t\",usecols=list(range(20))) # Storing data as a Pandas framework\n",
    "\n",
    "headers=[\"X0\",\"X1\",\"X2\",\"X3\",\"R0\",\"R1\",\"R2\",\"R3\",\"Gain\",\"Phase\",\"0_50Hz\",\"50_100Hz\",\"100_150Hz\",\"150_200Hz\",\"200_250Hz\",\"250_300Hz\",\"300_350Hz\",\"350_400Hz\",\"400_450Hz\",\"450_500Hz\"] \n",
    "data.columns = headers # Adding headers to the data\n",
    "\n",
    "data[\"Stability\"] = np.heaviside(data[\"0_50Hz\"]+data[\"50_100Hz\"]+data[\"100_150Hz\"]+data[\"150_200Hz\"]+data[\"200_250Hz\"]+data[\"250_300Hz\"]+data[\"300_350Hz\"]+data[\"350_400Hz\"]+data[\"400_450Hz\"]+data[\"450_500Hz\"],0).astype('int')\n",
    "\n",
    "# The stability column indicates whether a combustor is practically stable (0) or a practically unstable (1).\n",
    "\n",
    "# Let's drop the unused columns\n",
    "data=data.drop(columns=['X0','R3',\"0_50Hz\",\"50_100Hz\",\"100_150Hz\",\"150_200Hz\",\"200_250Hz\",\"250_300Hz\",\"300_350Hz\",\"350_400Hz\",\"400_450Hz\",\"450_500Hz\"])\n",
    "\n",
    "# X represents the absolute axial position of the element. Let's compute Li=Xi-Xi-1 corresponding to the length of each element.\n",
    "\n",
    "data['X3']=data['X3']-data['X2']\n",
    "data['X2']=data['X2']-data['X1']\n",
    "\n",
    "data.rename(columns={\"X1\":\"L1\"}, inplace=True) # We just need to change the heading for this one\n",
    "data.rename(columns={\"X2\":\"L2\"}, inplace=True) # We just need to change the heading for this one\n",
    "data.rename(columns={\"X3\":\"L3\"}, inplace=True) # We just need to change the heading for this one\n",
    "\n",
    "#data=data[:100] # FOR VALIDATION ONLY - Select the first 100 examples\n",
    "\n",
    "print(\"\\nTop 10 lines of the pre-processed data:\\n\",file=sourceFile)\n",
    "print(round(data.head(10),4).to_markdown(index = False, tablefmt=\"fancy_grid\"),file=sourceFile)\n",
    "\n",
    "data.head(10) # Display the top 10 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L1           float64\n",
       "L2           float64\n",
       "L3           float64\n",
       "R0           float64\n",
       "R1           float64\n",
       "R2           float64\n",
       "Gain         float64\n",
       "Phase        float64\n",
       "Stability      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes # Checking the data types for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "149701 stable configurations - 401656 unstable configurations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n{} stable configurations - {} unstable configurations.\\n\".format(data[\"Stability\"].value_counts()[0],data[\"Stability\"].value_counts()[1]),file=sourceFile)\n",
    "print(\"\\n{} stable configurations - {} unstable configurations.\\n\".format(data[\"Stability\"].value_counts()[0],data[\"Stability\"].value_counts()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Computing the Kendall correlation coefficients\n",
    "\n",
    "Kendall_corr=data.corr(method='kendall') # Compute the correlation between the different variables\n",
    "Kendall_corr.to_csv(r'Kendall_correlations_Binary.csv', index = False) # Storing to a data file\n",
    "\n",
    "print(\"Correlations between the different variables:\\n\",file=sourceFile)\n",
    "print(round(Kendall_corr,3).to_markdown(index = True, tablefmt=\"fancy_grid\"),file=sourceFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Machine Learning setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(551357, 8)\n",
      "(551357,)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------------------------------------------------------------\\n\",file=sourceFile)\n",
    "print(\"Step 2 : Machine Learning setup\\n\".upper(),file=sourceFile)\n",
    "\n",
    "# Defining the feature matrix and response vectors\n",
    "\n",
    "X=data[['L1','L2','L3','R0','R1','R2','Gain','Phase']].values # Feature Matrix\n",
    "y=data[\"Stability\"].values # Response vector\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the feature vector\n",
    "\n",
    "X=preprocessing.StandardScaler().fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set Feature Matrix (441085, 8)\n",
      "Size of testing set Feature Matrix (110272, 8)\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=3)\n",
    "print('Size of training set Feature Matrix {}'.format(X_train.shape),file=sourceFile)\n",
    "print('Size of testing set Feature Matrix {}'.format(X_test.shape),file=sourceFile)\n",
    "print('Size of training set Feature Matrix {}'.format(X_train.shape))\n",
    "print('Size of testing set Feature Matrix {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: K-nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest testing accuracy is 99.295 % obtained for 1 neighbour(s)\n",
      "\n",
      "Elapsed time: 747.94 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------------------------------------------------------------\\n\",file=sourceFile)\n",
    "print(\"Step 3 : K-nearest neighbours\\n\".upper(),file=sourceFile)\n",
    "\n",
    "## Building the K nearest neighbours (KNN) models\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "Ks=50 # Maximum number of neighbours\n",
    "\n",
    "parameters_Kneigh = [\n",
    "    {\n",
    "        'n_neighbors': range(1,Ks+1),\n",
    "    },\n",
    "]\n",
    "\n",
    "#KNeighborsClassifier().get_params()\n",
    "\n",
    "search_Kneigh = GridSearchCV(KNeighborsClassifier(), parameters_Kneigh, scoring='accuracy', n_jobs=-1)\n",
    "search_Kneigh.fit(X_train,y_train)\n",
    "\n",
    "pred_Kneigh_test = search_Kneigh.predict(X_test)\n",
    "mean_acc_test=metrics.accuracy_score(y_test,pred_Kneigh_test)\n",
    "\n",
    "print(\"The highest testing accuracy is\",round(100*mean_acc_test,3),\"% obtained for\",search_Kneigh.best_params_['n_neighbors'], \"neighbour(s)\",file=sourceFile)\n",
    "print(\"Elapsed time:\",round((time.time() - t),2),\"seconds\",file=sourceFile)\n",
    "\n",
    "print(\"The highest testing accuracy is\",round(100*mean_acc_test,3),\"% obtained for\",search_Kneigh.best_params_['n_neighbors'], \"neighbour(s)\")\n",
    "print(\"\\nElapsed time:\",round((time.time() - t),2),\"seconds\")\n",
    "\n",
    "result_Kneigh=search_Kneigh.cv_results_['mean_test_score']\n",
    "np.savetxt(\"Results_Kneigh_Binary.csv\", result_Kneigh, delimiter=\",\") # Saving results to a separate file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest testing accuracy is 99.381 % obtained for 46 layer(s)\n",
      "\n",
      "Elapsed time: 93.13 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------------------------------------------------------------\\n\",file=sourceFile)\n",
    "print(\"Step 4 : Decision Trees\\n\".upper(),file=sourceFile)\n",
    "\n",
    "## Building the Decision Trees models\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "Ks=50 # Maximum number of layers\n",
    "\n",
    "parameters_Tree = [\n",
    "    {\n",
    "        'max_depth': range(1,Ks+1),\n",
    "    },\n",
    "]\n",
    "\n",
    "search_Tree = GridSearchCV(DecisionTreeClassifier(criterion=\"entropy\"), parameters_Tree, scoring='accuracy', n_jobs=-1)\n",
    "search_Tree.fit(X_train,y_train)\n",
    "\n",
    "pred_Tree_test = search_Tree.predict(X_test)\n",
    "mean_acc_test=metrics.accuracy_score(y_test,pred_Tree_test)\n",
    "\n",
    "print(\"The highest testing accuracy is\",round(100*mean_acc_test,3),\"% obtained for\",search_Tree.best_params_['max_depth'], \"layer(s)\",file=sourceFile)\n",
    "print(\"Elapsed time:\",round((time.time() - t),2),\"seconds\",file=sourceFile)\n",
    "\n",
    "print(\"The highest testing accuracy is\",round(100*mean_acc_test,3),\"% obtained for\",search_Tree.best_params_['max_depth'], \"layer(s)\")\n",
    "print(\"\\nElapsed time:\",round((time.time() - t),2),\"seconds\")\n",
    "\n",
    "result_Tree=search_Tree.cv_results_['mean_test_score']\n",
    "np.savetxt(\"Results_Tree_Binary.csv\", result_Tree, delimiter=\",\") # Saving results to a separate file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgaudron/anaconda3/envs/JupyterLab_env/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest testing accuracy is 99.555 % obtained for 95 tree(s)\n",
      "\n",
      "Elapsed time: 2530.31 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------------------------------------------------------------\\n\",file=sourceFile)\n",
    "print(\"Step 5 : Random forests\\n\".upper(),file=sourceFile)\n",
    "\n",
    "## Building the Random forest models for various numbers of trees in the forest\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "Ks=100 # Maximum number of trees in the forest\n",
    "\n",
    "parameters_Forest = [\n",
    "    {\n",
    "        'n_estimators': range(1,Ks+1),\n",
    "    },\n",
    "]\n",
    "\n",
    "search_Forest = GridSearchCV(RandomForestClassifier(criterion='entropy'), parameters_Forest, scoring='accuracy', n_jobs=-1)\n",
    "search_Forest.fit(X_train,y_train)\n",
    "\n",
    "pred_Forest_test = search_Forest.predict(X_test)\n",
    "mean_acc_test=metrics.accuracy_score(y_test,pred_Forest_test)\n",
    "\n",
    "print(\"The highest testing accuracy is\",round(100*mean_acc_test,3),\"% obtained for\",search_Forest.best_params_['n_estimators'], \"tree(s)\",file=sourceFile)\n",
    "print(\"Elapsed time:\",round((time.time() - t),2),\"seconds\",file=sourceFile)\n",
    "\n",
    "print(\"The highest testing accuracy is\",round(100*mean_acc_test,3),\"% obtained for\",search_Forest.best_params_['n_estimators'], \"tree(s)\")\n",
    "print(\"\\nElapsed time:\",round((time.time() - t),2),\"seconds\")\n",
    "\n",
    "result_Forest=search_Forest.cv_results_['mean_test_score']\n",
    "np.savetxt(\"Results_Forest_Binary.csv\", result_Forest, delimiter=\",\") # Saving results to a separate file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Multilayer Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest testing accuracy is 98.235 % obtained with alpha= 0.001 and initial learning rate= 0.001\n",
      "\n",
      "Elapsed time: 28678.36 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------------------------------------------------------------------------------------------------------------------------\\n\",file=sourceFile)\n",
    "print(\"Step 6 : Multilayer Perceptrons\\n\".upper(),file=sourceFile)\n",
    "\n",
    "## Building the Multilayer Perceptron models for various hyperparameters\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "parameters_MLP = [\n",
    "    {\n",
    "        'alpha': [0.001, 0.003, 0.01, 0.03, 0.1, 0.3],  # Regularisation parameter\n",
    "        'learning_rate_init': [0.0001, 0.0003, 0.001, 0.003, 0.006, 0.01], # Initial learning rate\n",
    "    },\n",
    "]\n",
    "\n",
    "search_MLP = GridSearchCV(MLPClassifier(solver='adam', activation='relu', hidden_layer_sizes=(100,100,100),random_state=1, max_iter=10000, verbose=False, tol=1e-4, batch_size='auto'), parameters_MLP, scoring='accuracy', n_jobs=-1)\n",
    "search_MLP.fit(X_train,y_train)\n",
    "\n",
    "pred_MLP_test = search_MLP.predict(X_test)\n",
    "mean_acc_test=metrics.accuracy_score(y_test,pred_MLP_test)\n",
    "\n",
    "print(\"The highest testing accuracy is\",round(100*mean_acc_test,3),\"% obtained with alpha=\",search_MLP.best_params_['alpha'], \"and initial learning rate=\",search_MLP.best_params_['learning_rate_init'],file=sourceFile)\n",
    "print(\"Elapsed time:\",round((time.time() - t),2),\"seconds\",file=sourceFile)\n",
    "\n",
    "print(\"The highest testing accuracy is\",round(100*mean_acc_test,3),\"% obtained with alpha=\",search_MLP.best_params_['alpha'], \"and initial learning rate=\",search_MLP.best_params_['learning_rate_init'])\n",
    "print(\"\\nElapsed time:\",round((time.time() - t),2),\"seconds\")\n",
    "print(\"\\n----------------------------------------------------------------------------------------------------------------------------\\n\",file=sourceFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Closing the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceFile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
